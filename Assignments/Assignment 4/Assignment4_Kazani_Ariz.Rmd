---
title: "Assignment 4"
author: "Ariz Kazani"
date: "`r Sys.Date()`"
output: pdf_document
---

# Assignment 4

## Name: Ariz Kazani

## Student ID: 101311311

------------------------------------------------------------------------

# Notes

```{r}
# Libraries

# NOTE: if you do not have any of the below libraries installed, 
# un-comment the line and run it

# install.packages("rmarkdown")
library(rmarkdown)

# install.packages("ggplot2")
library(ggplot2)

# install.packages("lpSolve")
library(lpSolve)

# useful libraries not required for this assignment
# install.packages("patchwork")
# library(patchwork)

# install.packages("dplyr")
# library(dplyr)

# install.packages("tidyr")
# library(tidyr)

# install.packages("gapminder")
# library(gapminder)

```

------------------------------------------------------------------------

# Solutions

------------------------------------------------------------------------

## 1. Discrete Probabilistic Modeling - Markov Chains

### A. Define a simple Markov Chain with 3 states: A, B, and C. Create a transition matrix where the probability of transitioning from any state to another is as follows:

-   P(A -\> B) = 0.3, P(A -\> C) = 0.7
-   P(B -\> A) = 0.6, P(B -\> C) = 0.4
-   P(C -\> A) = 0.8, P(C -\> B) = 0.2

```{r}

pTrans <- matrix(c(
  0, 0.6, 0.8,
  0.3, 0, 0.2,
  0.7, 0.4, 0
), nrow = 3, byrow = TRUE)

pTrans
```

### B. Write an R function to simulate the Markov Chain for 100 steps starting from state A. Plot the state

transitions over time.

```{r}
simMC <- function(tMatrix, start, numRow, numSteps) {
  states <- numeric(numSteps + 1) 
  states[1] <- sample(1:numRow, 1, prob = start)
  
  for (i in 1:numSteps) {
    states[i + 1] <- sample(1:numRow, 1, prob = tMatrix[, states[i]])
  }
  
  return(states)
}

x0 <- c(1, 0, 0) #start at A

set.seed(7)
totsim <- simMC(pTrans, x0, 3, 100)

plot(
  0:100 ,
  totsim,
  type = "p",
  pch = 19,
  lwd = 1,
  xlab = "Step #",
  ylab = "State Probability",
  main = "Marlkov Chain Simulation Over Steps"
)

```

### C. Compute the stationary distribution of the Markov Chain using the transition matrix.

```{r}
eigenVals <- eigen(pTrans)
statDist <- eigenVals$vectors[,1]
statDist <- statDist / sum(statDist)
statDist
```

### D. Verify the stationary distribution result by simulating the chain for a large number of steps (e.g., 10,000) and comparing the proportion of time spent in each state with the stationary distribution.

```{r}
set.seed(7)

lgSim <- simMC(pTrans, x0, 3, 10000)

ed <- table(lgSim) / length(lgSim)

cat("Simulated distribution", ed, "\n")
cat("Theoretical distribution", statDist, "\n")
```

------------------------------------------------------------------------

## 2. Discrete Probabilistic Modeling - Basic Monte Carlo Simulation

### A. Implement a basic Monte Carlo simulation to estimate the value of pi. Use the following steps:

1.  Generate a large number of random points within a unit square.
2.  Count the number of points that fall inside the unit circle.
3.  Use the ratio of points inside the circle to the total number of points to estimate pi.

```{r}
set.seed(7)
x <- runif(1000, -0.5, 0.5)
y <- runif(1000, -0.5, 0.5)

numI <- sum(x^2 + y^2 <= 0.25)

piE <- (numI / 250)
piE
```

### B. Write an R function to perform this simulation with 10,000 points.

```{r}
set.seed(7)

ePi <- function(count) {
  x <- runif(count, -0.5, 0.5)
  y <- runif(count, -0.5, 0.5)
  
  numI <- sum(x ^ 2 + y ^ 2 <= 0.25)
  
  piE <- (numI / (count/4))
  piE
}

ePi(10000)
```

### C. Plot the generated points, differentiating between points inside and outside the circle. Overlay the circle on the plot.

```{r}
set.seed(7)
x <- runif(1000, -0.5, 0.5)
y <- runif(1000, -0.5, 0.5)

plot(
  x,
  y,
  col = ifelse(x ^ 2 + y ^ 2 <= 0.25 , "green", "red"),
  pch = 19,
  main = "Estimating pi with Random points",
  xlab = "X",
  ylab = "Y",
  asp = 1
)

legend(
  legend = c("Inside Circle", "Outside Circle"),
  col = c("green", "red"),
  pch = 19,
   "topright"
)

```

### D. Calculate the estimated value of pi from your simulation and compare it to the true value of pi. Discuss the accuracy of the estimate.

```{r}
set.seed(7)
cat("Estimated Value of pi with 1000 random numbers", ePi(1000), "\n")
cat("Estimated Value of pi with 10000 random numbers", ePi(10000), "\n")
cat("Estimated Value of pi with 100000 random numbers", ePi(100000), "\n")
cat("Estimated Value of pi with 1000000 random numbers", ePi(1000000), "\n")
cat("Estimated Value of pi with 10000000 random numbers", ePi(10000000), "\n")
cat("Estimated Value of pi with 100000000 random numbers", ePi(100000000), "\n")

cat("True value of pi", 3.1415926)
```

As we can observe, the more points that are generated, the more accurate the simulations gets, with 100000000 points getting a accuracy of 5 digits. On a side note, each simulation to an exponentially greater time than the previous.

------------------------------------------------------------------------

## 3. Linear Programming

### A. Formulate the following linear programming problem: Maximize Z = 3x~1~ + 2x~2~ Subject to:

-   2x~1~ + x~2~ \<= 20
-   4x~1~ ‚àí 5x~2~ \>= ‚àí10
-   x~1~ + 2x~2~ \<= 15
-   x~1~, x~2~ \>= 0

```{r}
# Objective Function
# Z <- 3 * x1 + 2 * x2

# Constraints
# 2 * x1 + x2 <= 20
# 4 * x1 + 5 * x2 >= -10
# x1 + 2 * x2 <= 15
# x1 >= 0 && x2 >= 0
```

### B. Solve the linear programming problem using the lpSolve package in R. Provide the R code and solution.

```{r}
objective <- c(3, 2)
constraints <- matrix(c(2, 1, 4, 5, 1, 2), nrow = 3, byrow = TRUE)
rhs <- c(20, -10, 15)
directions <- c("<=", ">=", "<=")
solution <- lp("max", objective, constraints, directions, rhs)

solution$solution
solution$objval
```

### C. Interpret the solution, including the values of x1x_1x1 and x2x_2x2, and the maximum value of ZZZ.

(side note I have not clue what x1x_1x1, x2x_2x2 and ZZZ is so I'm going to assume its asking for x1, x2 and Z)

The max value of x1 and x2 are both greater than zero meaning that some x1s and some x2s are required to reach the maximum value, 31.666666 in this case. When performing an objective function coefficient analysis we can see that increasing either of the objective coefficients increased the maximum val and decreasing either had the opposite affect. Increasing the coefficient of x1 to \>= 4 made the optimal x2 value 0. When performing a RHS analysis we can see that the maximum increases the when you increase the first and last numbers, decreased them had the opposite effect, where moving the middle number up to 50 and down to -99999 had no effect, moving the middle number any higher causes the maximum value become 0 with optimal values for x1 and x2 also becoming 0. When performing a constraint coefficient analysis we can see that increasing the coefficients of the first restriction reduces the maximum value, decreasing them has the opposite affect. Increasing the coefficients in the second restriction had no affect and decreasing the coefficients decreased the maximum value. The coefficients in the last restriction behaved like the first restriction.

------------------------------------------------------------------------

## 4. Integer Programming

### A. Formulate the following integer programming problem: Maximize ùëç = 4x~1~ + 3x~2~ Subject to:

-   3x~1~ + 2x~2~ \<= 12
-   x~1~ ‚àí x~2~ \>= 1
-   x~1~, x~2~ \>= 0 and integers

```{r}
# Objective Function
# Z <- 4 * x1 + 3 * x2

# Constraints
# 3 * x1 + 2 * x2 <= 12
# x1 + x2 >= 1
# x1 >= 0 && x2 >= 0 && x1 %% 1 == 0 && x2 %% 1 == 0

```

### B. Solve the integer programming problem using the ompr package in R. Provide the R code and solution.

```{r}
objective <- c(4, 3)
constraints <- matrix(c(3, 2, 1, 1), nrow = 2, byrow = TRUE)
rhs <- c(12, 1)
directions <- c("<=", ">=")
solution <- lp("max", objective, constraints, directions, rhs, all.int = TRUE)

solution$solution
solution$objval
```

### C. Interpret the solution, including the values of x~1~ and x~2~, and the maximum value of Z.

The max value of x1 is 0, and x2 is greater than zero meaning that 0 x1s and some x2s are required to reach the maximum value, 18 in this case.

When performing an objective function coefficient analysis we can see that increasing either of the objective coefficients increased the maximum val and decreasing either had the opposite affect. When performing a RHS analysis we can see that increasing the first number increases the maximum value, decreased opposite effect. where moving the second number up to 6 and down to -99999 had no effect, moving the second number any higher causes the maximum value to become 0 with optimal values for x1 and x2 also becoming 0. When performing a constraint coefficient analysis we can see that increasing the coefficients of the first as no effect for the first one and the second one causes the maximum value to go to zero, decreasing them causes the maximum value. Increasing the coefficients in the second restriction had no affect and decreasing the coefficients decreased the maximum value, only for the second one in the second restriction.

### D. Discuss the differences between the linear and integer programming solutions and the situations in which integer programming is necessary.

The difference between Linear programming is that linear programming will usually find a value greater than integer programming. Linear programming is also continuous where as integer programming is discrete, as a result integer programming is required when we want to find whole or discrete values, such as the optimal number of parts to produce. Linear programming is good for values that could be continuous or not whole values, such as the most cost effective length of a road or optimal temperature to grow roses.

------------------------------------------------------------------------

## 5. Bootstrap Methods

### A. Use the bootstrap method to estimate the mean and 95% confidence interval of the following dataset:

data \<- c(5.1, 4.9, 5.7, 5.5, 5.0, 4.8, 5.2, 5.6, 4.7, 5.3)

Write an R function to perform bootstrap resampling and calculate the mean for each resample. Perform 10,000 bootstrap resamples.

```{r}

```

### B. Construct a histogram of the bootstrap means and calculate the 95% confidence interval for the mean based on the bootstrap samples.

```{r}

```

### C. Compare the bootstrap confidence interval with the theoretical confidence interval based on the normal distribution. Discuss any differences.

```{r}

```

### D. Evaluate the impact of the sample size on the bootstrap confidence interval by repeating the bootstrap process with different sample sizes (e.g., n=5, n=20) and comparing the results.

```{r}

```

------------------------------------------------------------------------

## 6. Bootstrap Methods - Regression

### A. Consider the following dataset:

```         
set.seed(123)
x <- rnorm(100)
y <- 2 + 3*x + rnorm(100)
```

Fit a linear regression model ùë¶ = B~0~ + B~1~ x + e and use bootstrap resampling to estimate the standard errors of the regression coefficients.

```{r}

```

### B. Perform 10,000 bootstrap resamples and calculate the standard errors for B~0~ and B~1~.

```{r}

```

### C. Compare the bootstrap standard errors with the standard errors obtained from the original regression model.

```{r}

```

### D. Evaluate the impact of the sample size on the bootstrap standard errors by repeating the bootstrap process with different sample sizes (e.g., n=50, n=200) and comparing the results.

```{r}

```
